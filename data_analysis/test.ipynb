{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import pickle\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from os.path import join, exists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_FOLDER = \"/home/cdragancea/MastersThesis/FBACode/analyze\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = dict()\n",
    "analyze_summary = dict()\n",
    "\n",
    "with open(f\"{FEATURES_FOLDER}/analyze_summary.json\", \"r\") as fin:\n",
    "    analyze_summary = json.load(fin)\n",
    "\n",
    "counter = 0\n",
    "for project_name in os.listdir(FEATURES_FOLDER):\n",
    "    # print(f\"Loading overall_stats for {project_name}\")\n",
    "    # if project_name == \"analyze_summary.json\":\n",
    "    # if project_name == \"analyze_summary.json\" or project_name == \"analyze_summary2.json\":\n",
    "    if project_name.startswith(\"analyze_summary\") or project_name.startswith(\"job_distribution\"):\n",
    "        continue\n",
    "    if not exists(join(FEATURES_FOLDER, project_name, 'overall_stats')) or project_name not in analyze_summary:\n",
    "        print(f\"Skipping {project_name} because it does not have overall_stats.\")\n",
    "        counter += 1\n",
    "        # if project_name in analyze_summary:\n",
    "        #     analyze_summary.pop(project_name)\n",
    "        # shutil.rmtree(join(FEATURES_FOLDER, project_name), ignore_errors=True)\n",
    "        continue\n",
    "    if analyze_summary[project_name][\"analysis status\"] != \"success\":\n",
    "        continue\n",
    "\n",
    "    with open(join(FEATURES_FOLDER, project_name, 'overall_stats')) as f:\n",
    "        content = f.read()\n",
    "    try:\n",
    "        overall_stats = json.loads(content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        str_err = str(e)\n",
    "        line = int(str_err.split()[3]) - 1\n",
    "    \n",
    "    individual_features = json.loads('\\n'.join(content.split('\\n')[:line]))\n",
    "    overall_features = json.loads('\\n'.join(content.split('\\n')[line:]))\n",
    "    stats[project_name] = {\n",
    "        'individual_features': individual_features,\n",
    "        'overall_features': overall_features\n",
    "    }\n",
    "\n",
    "project_names = list(stats.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_files_map = dict()\n",
    "\n",
    "def load_all_feature_files():\n",
    "    global feature_files_map\n",
    "\n",
    "    files = glob.glob(f\"{FEATURES_FOLDER}/**/*.ast.json\", recursive = True)\n",
    "    for i, file in enumerate(files):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Loaded {i} files\")\n",
    "\n",
    "        if i == 15000:\n",
    "            break\n",
    "        file_project_name = file.split(\"/\")[6]\n",
    "        if file_project_name not in stats:\n",
    "            print(f\"{file_project_name} project is not in stats dict\")\n",
    "            continue\n",
    "        try:\n",
    "            with open(file, \"r\") as fin:\n",
    "                data = json.load(fin)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception: {e}\")\n",
    "            print(f\"Skipping file: {file}\")\n",
    "            continue\n",
    "        feature_files_map[file] = data\n",
    "    \n",
    "    print(f\"Loaded {len(feature_files_map)} feature files\")\n",
    "    pickle.dump(feature_files_map, open(\"feature_files_map.pkl\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 files\n",
      "Loaded 1000 files\n",
      "Loaded 2000 files\n",
      "Loaded 3000 files\n",
      "Loaded 4000 files\n",
      "Loaded 5000 files\n",
      "Loaded 6000 files\n",
      "Loaded 7000 files\n",
      "Loaded 8000 files\n",
      "Loaded 9000 files\n",
      "Loaded 10000 files\n",
      "Loaded 11000 files\n",
      "Loaded 12000 files\n",
      "Loaded 13000 files\n",
      "Loaded 14000 files\n",
      "Loaded 15000 files\n",
      "Loaded 15000 feature files\n"
     ]
    }
   ],
   "source": [
    "load_all_feature_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_feature_files_map = pickle.load(open(\"feature_files_map.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
